FairNow's AI governance platform serves as a single source of truth for managing AI governance, risk, and compliance.
Many organisations today are leveraging AI in a distributed way across many different teams and departments. FairNow’s AI governance platform is an organisation’s AI governance command centre, serving as a single source of truth for managing AI governance, risk, and compliance. Risk, legal, data, technology, and business leaders can review their AI risks, track usage, monitor dependencies, and ensure compliance all within a single platform.
Core features of FairNow’s platform include AI inventory management; management of governance workflows, roles, and accountabilities; risk assessments; testing and ongoing monitoring; documentation and audit trails; vendor AI risk management; and regulatory compliance tracking. Organisations integrate the platform into their day-to-day governance activities, leveraging FairNow’s built-in functionality to automate governance tasks, simplify their compliance tracking and reporting, and centralise their oversight of AI risk.
Organisations using the platform today leverage a combination of off-the-shelf capabilities and configurable features. For example, many organisations adopt FairNow’s risk, regulatory, and compliance intelligence offerings to stay informed of potential risks for each of their AI applications, as well as in-scope laws and regulations; they also add their own incremental risk assessment questions, policies, and controls to ensure that AI usage is adhering to requirements that are specific to their own organisations.
More information on the AI White Paper Regulatory Principles
By tracking an organisation’s AI inventory and usage, the FairNow AI governance platform helps organisations determine the appropriate safety and reliability checks. These checks are logged on the FairNow platform to ensure that these safeguards are applied throughout the AI lifecycle and that a record of compliance is documented and maintained.
This is done in two ways. First, through tracking which regulations apply to the organisation’s AI and which voluntary standards the organisation follows, we explain which safety, reliability and robustness checks should be followed as part of these frameworks. The platform tracks these various checks.
Second, FairNow’s proprietary risk assessment logic identifies scenarios in which an AI system poses certain classes of risks related to safety, security, and robustness. The platform explains the risk and recommends potential mitigations to manage the risk.
By providing a single source of truth for overall AI governance, organisations can establish a transparent AI governance program. Multiple governance controls help developers and deployers of AI to provide the right level of transparency, notification and explainability to stakeholders; and documentation/approvals stored centrally on the platform ensures organisations maintain robust audit trails. FairNow has built in several model interpretability features to the platform that can help organisations understand the factors that drive their AI.
The platform automates multiple types of bias testing in alignment with regulatory expectations and best practices. The first is a disparate impact assessment analysis, which is automated by the platform and reports differences in selection rate or model scoring rate across demographic groups. The second is an explainability analysis which helps organisations understand the drivers behind model decisions, which can help determine the extent to which the model bases its decisions on demographic information versus valid and application-relevant criteria. The third is a chatbot bias assessment, which evaluates chatbots for differences in quality of responses between different demographic groups.
Additionally, the platform tracks AI-related laws and regulations to determine which apply to the organisation’s AI, so that they can adhere to the appropriate fairness requirements for which they are in scope.
Through a set of roles and responsibilities, workflows, and controls, the platform ensures that accountability is established. Organisations can establish multiple roles, set multi-step approval authority, and leverage FairNow’s platform to automate notifications and alerts in the event that gaps are identified for a particular AI application or at the organisational level.
As a company with decades of combined experience in model risk management and AI governance, we understand how challenging AI governance can be – and how cumbersome it can be without the right tools and automation. Establishing workflows based on industry best practice and in alignment with standards like NIST and ISO while allowing organisations to configure key parts of their AI governance program ensures the platform can serve organisations of all sizes, industries, and maturity levels.
With the many different ways that AI can be used across a wide organsation, tracking risk in a centralised manner can be cumbersome and time-consuming. Organisations without the right tools in place can end up tracking their AI inventory and risk across spreadsheets and shared drives. This results in hours spent manually managing processes, increasing the risk of human error and the possibility that something important may fall through the cracks.
FairNow’s AI governance platform is designed to help organisations track their AI systems and associated risks, whether managing an inventory of five or 500 applications.
AI risk assessments allow organisations to evaluate each application’s specific components and risk factors, assigning appropriate risk levels. The platform’s testing and monitoring features support compliance with global AI laws and regulations, ensuring that AI systems are effective, safe, and fair. Documentation and audit trails provide transparency for internal stakeholders and impacted populations. Vendor AI risk management helps companies ensure that the AI they procure meets international standards. Additionally, regulatory and compliance tracking is essential for those who fall under the jurisdiction of any of the growing number of AI regulations that are in effect across the globe.
AI governance platforms and technologies are designed to simplify, streamline, and automate various aspects of the governance process. However, human oversight—both of individual AI applications and the overall governance program—is essential for effectively managing existing and emerging AI risks within an organisation. Platforms like FairNow should be used to facilitate and enhance, rather than replace, human oversight in identifying, managing, and mitigating AI risks in line with internal and external requirements.