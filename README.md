# ğŸ§  Ethical Risk Detector (Responsible AI by Design)

A full-featured NLP pipeline to detect **ethical risks** in UK government AI policy documents using **weak supervision** and **transformer-based models**. The system identifies textual indicators of:

- ğŸ” **Bias**
- ğŸ“¹ **Surveillance**
- ğŸ§¾ **Lack of Transparency**

---

## ğŸ“ Project Structure

```
ethical-risk-detector/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Unprocessed .txt files scraped from gov.uk
â”‚   â”œâ”€â”€ cleaned/        # Preprocessed JSON files
â”‚   â””â”€â”€ processed/      # Labeled CSVs ready for model training
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scrapping/              # Web scrapers (e.g., govuk_scraper.py)
â”‚   â”œâ”€â”€ preprocessing/          # Text cleaning logic
â”‚   â”œâ”€â”€ labeling/               # Snorkel labeling functions
â”‚   â”œâ”€â”€ models/                 # Model training and evaluation
|   â”œâ”€â”€ config.py               # Global paths and constants
â”‚   â””â”€â”€ data_loader.py          # Load data
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ label_cleaned_data.py   # Apply labeling
â”‚   â””â”€â”€ run_inference.py        # Run predictions on new text
â”‚
â”œâ”€â”€ logs/               # Training logs
â”œâ”€â”€ models/             # Saved model checkpoints
â”œâ”€â”€ requirements.txt    # Required packages
â”œâ”€â”€ README.md           # Project overview (this file)
â””â”€â”€ .env                # Local environment variables (not versioned)
```

---

## ğŸ› ï¸ Setup

### 1. Clone & Install Dependencies

```bash
git clone https://github.com/your-org/ethical-risk-detector.git
cd ethical-risk-detector
pip install -r requirements.txt
```

### 2. Install Key Libraries

```bash
pip install torch torchvision torchaudio
pip install transformers datasets snorkel scikit-learn
```

---

## âš™ï¸ Pipeline Usage

### Step 1: Scrape Raw Data

```bash
python scripts/scrape_data.py
```

### Step 2: Clean and Preprocess

```bash
python scripts/clean_data.py
```

### Step 3: Apply Snorkel Labeling Functions

```bash
python scripts/label_cleaned_data.py
```

### Step 4: Train Roberta Multi-label Classifier

```bash
python -m src.models.trainer
```

### Step 5: Run Inference

```bash
python scripts/run_inference.py
```

Youâ€™ll be prompted to enter text:

```
Enter text: AI models trained on historical data may reinforce discrimination.
Predicted Risks: {'bias': 1, 'surveillance': 0, 'transparency': 1}
```

---

## ğŸ¤– Model Details

- **Model**: `RobertaForSequenceClassification`
- **Type**: Multi-label classification (3 labels: bias, surveillance, transparency)
- **Loss**: `BCEWithLogitsLoss`
- **Input**: Preprocessed policy document text
- **Output**: Risk probabilities â†’ binary labels (threshold = 0.5)

---

## ğŸ§  Snorkel Labeling Functions

Weak supervision is used to auto-label examples using rules in `src/labeling/snorkel_rules.py`. Key functions include:

- `bias_keywords()`: Flags fairness, systemic bias, social discrimination
- `surveillance_keywords()`: Flags tracking, facial recognition, mass monitoring
- `transparency_keywords()`: Flags black-box warnings, lack of audit/explainability

---

## âœ… Example Output

| id        | title                            | bias | surveillance | transparency |
| --------- | -------------------------------- | ---- | ------------ | ------------ |
| govuk_001 | AI Regulation                    | 1    | 0            | 1            |
| govuk_002 | Facial Recognition in Public Use | 0    | 1            | 0            |

---

## ğŸ”­ Future Work

- SHAP/LIME-based interpretability
- Human-in-the-loop review interface
- Fine-tuning on manually annotated corpus
- Zero-shot inference using TARS/BART

---

## ğŸ‘¤ Author

**Muhammad Zain Ul Abideen**  
ğŸ’¼ Full Stack AI Developer  
ğŸ“§ zainm2432003@gmail.com
